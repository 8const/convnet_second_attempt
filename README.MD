Currently I've got functions that map a convolution to an equivalent dot product and back.


And it's enough to optimise kernels with mini batch (currently size 1) gradient descent


Read the pdf for why questions.


Looks like this time i'll make it. It can already learn kernels.


Next step is to write a nice function that differentiates a whole minibatch. 

